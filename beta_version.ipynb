{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "beta_version.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5CwEh9WsHsJ"
      },
      "source": [
        "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
        "from keras.layers import Activation, Dense, Dropout, Flatten, InputLayer\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from skimage.color import rgb2lab, lab2rgb, rgb2gray\n",
        "from skimage.io import imsave\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "disable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlXRFpkctmoR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbbcf7c3-efdd-4fd3-810c-bde44ed92f5b"
      },
      "source": [
        "# mount your drive once per colab session\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# !unzip '/content/drive/My Drive/train'.zip -d '/content/drive/My Drive/' # only need to do once for train and test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Drlf15YqMcXV"
      },
      "source": [
        "# unzip the test files!\n",
        "#!unzip '/content/drive/My Drive/test'.zip -d '/content/drive/My Drive/' # only need this once"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wv2PNJfsHsO"
      },
      "source": [
        "# factor needed for cifar10\n",
        "factor = int(256/32)\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(int(256 / factor), int(256 / factor), 1)))\n",
        "model.add(Conv2D(64/factor, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(64/factor, (3, 3), activation='relu', padding='same', strides=2))\n",
        "model.add(Conv2D(128/factor, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(128/factor, (3, 3), activation='relu', padding='same', strides=2))\n",
        "model.add(Conv2D(256/factor, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256/factor, (3, 3), activation='relu', padding='same', strides=2))\n",
        "model.add(Conv2D(512/factor, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256/factor, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(128/factor, (3, 3), activation='relu', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(Conv2D(64/factor, (3, 3), activation='relu', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(Conv2D(32/factor, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.compile(optimizer='rmsprop', loss='mse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EijDV19Asnik",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "1fd39d07-e9e0-4cef-e093-a232b5ee8db8"
      },
      "source": [
        "# Get images, colab\n",
        "X = []\n",
        "i = 0\n",
        "for filename in os.listdir('/content/drive/My Drive/train'):\n",
        "  X.append(img_to_array(load_img('/content/drive/My Drive/train/'+filename)))\n",
        "    \n",
        "X = np.array(X, dtype=float)\n",
        "\n",
        "# Set up train and test data\n",
        "Xtrain = X[:len(X) - 1]\n",
        "Xtrain = 1.0/255*Xtrain\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-581dfbf57d5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/train/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error: '/content/drive/My Drive/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR-5qGaosHsP"
      },
      "source": [
        "# Set up train and test data\n",
        "split = int(0.95*len(X))\n",
        "Xtrain = X[:split]\n",
        "\n",
        "#splitting validation\n",
        "Xtrain = 1.0/255*Xtrain\n",
        "split_idx = int(0.9*len(Xtrain))\n",
        "Xvalid=Xtrain[split_idx:]\n",
        "Xtrain=Xtrain[:split_idx]\n",
        "\n",
        "# Image transformer\n",
        "batch_size = 100\n",
        "def train_generator(batch_size):\n",
        "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
        "        lab_batch = rgb2lab(batch)\n",
        "        X_batch = lab_batch[:,:,:,0]\n",
        "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
        "        yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch)\n",
        "\n",
        "def validationGenerator(batch_size):\n",
        "    for batch in datagen.flow(Xvalid, batch_size=batch_size):\n",
        "        lab_batch = rgb2lab(batch)\n",
        "        X_batch = lab_batch[:,:,:,0]\n",
        "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
        "        yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch)\n",
        "\n",
        "# new stuff from Naveen\n",
        "steps_per_epoch = int(len(Xtrain)/batch_size)\n",
        "validation_steps = int(len(Xvalid)/batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWetkqaKsHsP"
      },
      "source": [
        "# Train model   \n",
        "\n",
        "filepath = \"/content/drive/My Drive/Model/model.h5\"\n",
        "\n",
        "#model.load_weights(filepath)\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "callbacks_list = [es,checkpoint]\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=\"output/first_run\")\n",
        "model.fit(train_generator(batch_size), callbacks=callbacks_list, epochs=1000, steps_per_epoch=steps_per_epoch,\n",
        "          validation_data=validationGenerator(batch_size), validation_steps=validation_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QclOqv8vsHsQ"
      },
      "source": [
        "# Save model\n",
        "model_json = model.to_json()\n",
        "with open(\"/content/drive/My Drive/Model/model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"/content/drive/My Drive/Model/model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fXD7J-RsHsQ"
      },
      "source": [
        "# Test images for cifar-10\n",
        "files_sorted = os.listdir('/content/drive/My Drive/test')\n",
        "files_sorted = [x for x in files_sorted if x.endswith(\".png\")]\n",
        "files_sorted.sort(key=lambda x:int(x.split(\".\")[0]))\n",
        "\n",
        "color_me = []\n",
        "#should be after your training data\n",
        "for i in range(1,1000):\n",
        "    filename = files_sorted[i]\n",
        "    fname = train_folder_cifar + filename\n",
        "    color_me.append(img_to_array(load_img(fname)))\n",
        "color_me = np.array(color_me, dtype=float)\n",
        "color_me = rgb2lab(1.0 / 255 * color_me)[:, :, :, 0]\n",
        "color_me = color_me.reshape(color_me.shape + (1,))\n",
        "\n",
        "# Test model\n",
        "output = model.predict(color_me)\n",
        "output = output * 128\n",
        "\n",
        "# Output colorizations\n",
        "for i in range(len(output)):\n",
        "    cur = np.zeros((int(256 / factor), int(256 / factor), 3))\n",
        "    cur[:, :, 0] = color_me[i][:, :, 0]\n",
        "    cur[:, :, 1:] = output[i]\n",
        "    imsave(\"/content/drive/My Drive/Results/\" + str(i+1) + \".png\", lab2rgb(cur))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "nfMjCra0sHsR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}